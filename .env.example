DATABASE_URL=postgresql+asyncpg://postgres:postgres@postgres:5432/youtube
SYNC_DATABASE_URL=postgresql+psycopg2://postgres:postgres@postgres:5432/youtube
REDIS_URL=redis://redis:6379/0

# Required: set your OpenAI API key
OPENAI_API_KEY=

LLM_MODEL=gpt-4o
LLM_MINI_MODEL=gpt-4o-mini
TRANSCRIPTION_MODEL=whisper-1

# LLM provider: "openai" | "local_ollama"
LLM_PROVIDER=openai

# Local Ollama settings (used when LLM_PROVIDER=local_ollama)
# On macOS Apple Silicon: run Ollama natively, containers reach it via host.docker.internal
# LOCAL_LLM_BASE_URL=http://host.docker.internal:11434/v1
# LOCAL_LLM_MODEL=llama3.1
# LOCAL_LLM_MINI_MODEL=qwen2.5:0.5b

CORS_ORIGINS=["http://localhost","http://localhost:3000"]
TMP_DIR=/tmp/app
